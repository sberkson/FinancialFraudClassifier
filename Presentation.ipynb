{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Financial Fraud Classifier\n",
    "#### Sam Berkson and Ben Puryear\n",
    "#### CPSC 322 Final Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mysklearn import myclassifiers, myevaluation, mypytable, myutils\n",
    "import importlib\n",
    "\n",
    "# set up the data for later usage\n",
    "importlib.reload(mypytable)\n",
    "\n",
    "# first we are going to import the dataset into a mypytable object\n",
    "mytable = mypytable.MyPyTable()\n",
    "mytable.load_from_file(\"input_data/Fraud_chop.csv\")\n",
    "\n",
    "# the values of type are strings, so we will convert them to ints to be able to be used in the classifiers\n",
    "mytable.convert_col_to_int('type')\n",
    "mytable.convert_col_to_int('amount')\n",
    "mytable.drop_cols(['step','nameOrig', 'nameDest']) # we dont need step, nameOrig, nameDest, isFlaggedFraud\n",
    "\n",
    "# we also will make x and y\n",
    "X = []\n",
    "y = []\n",
    "for row in mytable.data:\n",
    "    X.append(row[0:len(row)-1])\n",
    "    y.append(row[-1])\n",
    "\n",
    "# creating our training and test sets\n",
    "X_train_folds_indexes, X_test_folds_indexes = myevaluation.kfold_cross_validation(X,13) # 13 proved to be our most accurate # of folds\n",
    "\n",
    "X_test_folds, X_train_folds, y_test_folds, y_train_folds = myutils.indexes_to_fold(X_test_folds_indexes, X_train_folds_indexes, X, y)\n",
    "X_test, X_train, y_test, y_train = myutils.folds_to_train_test(X_test_folds, X_train_folds, y_test_folds, y_train_folds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction)  \n",
    "\n",
    "* Why are we doing this in the first place?\n",
    "    * The potential impact of our results are pretty intuitive.  Automated fraud detection systems have massive applications for both businesses as well as financial institutions.  A system like this could be used to stop fradulent activies, and help identify the perpetrators of financial crimes.  A system like ours would likely affect the following stakeholders:\n",
    "    * Consumers\n",
    "        * Consumer's financial assets gain increased security, and helps to increase trust in modern financial institutions which can help stimulate economic growth.\n",
    "    * Businesses\n",
    "        * Businesses can save needless expense by ensuring that they are not the victims of fradulent transactions out of company accounts, or the victims of fradulent orders.\n",
    "    * Financial Institutions\n",
    "        * Banks can automate the task of consumer protection, allowing them greater resources to pursue recovery of funds through all available avenues.\n",
    "    * Regulatory Agencies\n",
    "        * Regulatory agencies can work with financial institutions to share identifying information regarding fradulent transactions, and use this information to pursue recovery of funds through a variety of methods.  One cool method is through appoint a receiver to recover and equitably dispense recovered funds among secured and unsecured creditors, which Sam just so happens to do for work over the summer!\n",
    "    * Financial Criminals\n",
    "        * This gang isnt so lucky.  Criminals only gain determent from committing felonies and robbing consumers and instituions of their assets.\n",
    "\n",
    "    * Personal interest:\n",
    "        * Sam works with financial fraud on a daily basis for work\n",
    "\n",
    "![image](media/saftey.jpeg)\n",
    "\n",
    "* Dataset\n",
    "    * Our dataset originates from Kaggle, coming packaged as a csv file.  This csv file contains just over a million instances of different types of financial transactions from different accounts, and marks whether or not the transaction was flagged as fradulent or not, and whether or not the transaction was actually fradulent.  Our dataset contains 11 attributes:\n",
    "    * step\n",
    "        * Step maps to a number of hours, where 1 step is 1 hour\n",
    "     * type\n",
    "        * This identifies the type of transaction.  It can be: CASH-IN; CASH-OUT; DEBIT; PAYMENT; and TRANSFER.\n",
    "        * This could be a pretty useful attribute to use in classification.\n",
    "    * amount\n",
    "        * This is the amount of money transferred (in the local currency).\n",
    "        * This can also be a pretty useful attribute to use in our classification.\n",
    "    * nameOrig\n",
    "        * This identifies the customer who initiated the transaction.\n",
    "    * oldBalanceOrg\n",
    "        * This is the initial balance before the transaction.\n",
    "    * newBalanceOrig\n",
    "        * This is the new balance after the transaction.\n",
    "    * nameDest\n",
    "        * This identifies the recipient of the transfer.\n",
    "    * oldBalanceDest\n",
    "        * This is the initial balance recipient before the transaction\n",
    "    * newBalanceDest\n",
    "        * This is the new balance recipient after the transaction.\n",
    "        * This can be a useful tool for classification when used in comparison to oldBalanceDest for any given instance.\n",
    "    * isFraud\n",
    "        * This is the transactions made by the fraudulent agents inside the simulation. In this specific dataset the fraudulent behavior of the agents aims to profit by taking control or customers accounts and try to empty the funds by transferring to another account and then cashing out of the system.\n",
    "    * isFlaggedFraud\n",
    "        * The business model aims to control massive transfers from one account to another and flags illegal attempts. An illegal attempt in this dataset is an attempt to transfer more than $200.000$ in a single transaction.\n",
    "    \n",
    "Our classification goal is to correctly predict whether any given transaction is fradulent or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA)\n",
    "While we wont go over all of our EDA results, here are the cliffnotes and some interesting finds.\n",
    "\n",
    "__Attribute Distributions__\n",
    "\n",
    "* type\n",
    "\n",
    "![image](media/Transaction_Type_Distribution.jpeg) \n",
    "    \n",
    "* isFraud\n",
    "\n",
    "![image](media/Fradulent_Transaction_Distribution.jpeg)\n",
    "\n",
    "\n",
    "__Attribute Relationships__\n",
    "\n",
    "* oldBalanceOrg and newBalanceOrig\n",
    "    * slope: .6599, just about 2/3\n",
    "\n",
    "![image](media/Old_Balance_v_New_Balance.jpeg)\n",
    "\n",
    "* type and isFraud\n",
    "\n",
    "![image](media/Fraudulent_Transaction_Types_Distribution.jpeg)\n",
    "![image](media/Non-Fraudulent_Transaction_Types_Flagged_Distribution.jpeg)\n",
    "\n",
    "* type and isFlaggedFraud\n",
    "\n",
    "![image](media/Fraudulent_Transaction_Types_Flagged_Distribution.jpeg)\n",
    "![image](media/Non-Fraudulent_Transaction_Types_Flagged_Distribution.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average original balance: 833508.1312484784\n",
      "Average new balance: 1304552.5530755178\n",
      "Average difference: $ -471044.42182703933\n"
     ]
    }
   ],
   "source": [
    "oldBalanceDest = mytable.get_column('oldbalanceDest')\n",
    "newBalanceDest = mytable.get_column('newbalanceDest')\n",
    "amount = mytable.get_column('amount')\n",
    "\n",
    "avgOrgBalance = sum(oldBalanceDest)/len(oldBalanceDest)\n",
    "avgNewBalance = sum(newBalanceDest)/len(newBalanceDest)\n",
    "difference = avgOrgBalance - avgNewBalance\n",
    "avgTransfer = sum(amount)/len(amount)\n",
    "\n",
    "print(\"Average original balance:\", avgOrgBalance)\n",
    "print(\"Average new balance:\", avgNewBalance)\n",
    "print(\"Average difference: $\", difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances:  1642\n",
      "Number of fraudulent transactions: 821\n",
      "Number of non-fraudulent transactions: 821\n",
      "Number of fraudulent transactions flagged: 3\n",
      "Number of non-fraudulent transactions flagged: 1639\n",
      "Number of transaction types: 5\n",
      "Percentage of instances flagged as fradulent:  0.18270401948842874 %\n",
      "Number of instances correctly predicted:  824\n",
      "Number of instances incorrectly predicted:  818\n",
      "Accuracy:  50.18270401948843\n"
     ]
    }
   ],
   "source": [
    "isFlaggedFraud = mytable.get_column('isFlaggedFraud')\n",
    "isFraud = mytable.get_column(\"isFraud\")\n",
    "\n",
    "isFlaggedFraudT = 0\n",
    "isFlaggedFraudF = 0\n",
    "isFraudT = 0\n",
    "isFraudF = 0\n",
    "correctlyPredicted = 0\n",
    "incorrectlyPredicted = 0\n",
    "\n",
    "for index, value in enumerate(isFlaggedFraud):\n",
    "    if isFlaggedFraud[index] == 1:\n",
    "        isFlaggedFraudT += 1\n",
    "    else:\n",
    "        isFlaggedFraudF += 1\n",
    "        \n",
    "    if isFraud[index] == 1:\n",
    "        isFraudT += 1\n",
    "    else:\n",
    "        isFraudF += 1\n",
    "\n",
    "    if isFlaggedFraud[index] == 1 and isFraud[index] == 1:\n",
    "        correctlyPredicted += 1\n",
    "    elif isFlaggedFraud[index] == 0 and isFraud[index] == 0:\n",
    "        correctlyPredicted += 1\n",
    "    else:\n",
    "        incorrectlyPredicted += 1\n",
    "\n",
    "flagPercentage = (100 / 1642) * isFlaggedFraudT    \n",
    "print(\"Number of instances: \", isFraudT + isFraudF)\n",
    "print(\"Number of fraudulent transactions:\", isFraudT)\n",
    "print(\"Number of non-fraudulent transactions:\", isFraudF)\n",
    "print(\"Number of fraudulent transactions flagged:\", isFlaggedFraudT)\n",
    "print(\"Number of non-fraudulent transactions flagged:\", isFlaggedFraudF)\n",
    "print(\"Number of transaction types:\", 5)\n",
    "print(\"Percentage of instances flagged as fradulent: \", str(flagPercentage) + \" %\")\n",
    "print(\"Number of instances correctly predicted: \", correctlyPredicted)\n",
    "print(\"Number of instances incorrectly predicted: \", incorrectlyPredicted)\n",
    "print(\"Accuracy: \", (100 / 1642) * correctlyPredicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need a classifier accuracy greater than 50.2% in order to surpass the dataset's classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification)\n",
    "\n",
    "For our classification, we began by running all of our supervised learning classifiers over our training and test sets.  Since we are trying to predict whether a given transaction is fradulent or not, that means we're dealing with binary classification. We tracked the following metrics for all classifiers to measure accuracy:\n",
    "* Accuracy\n",
    "* Binary F1\n",
    "* Binary Precision\n",
    "* Binary Recall\n",
    "\n",
    "The results (rounded to the nearest hundredth) for each classifier are as follows:\n",
    "* Linear Regressor:\n",
    "    * Accuracy: $0.47$ or $47$%\n",
    "    * Binary F1: $0.44$\n",
    "    * Binary Precision: $0.47$\n",
    "    * Binary Recall: $0.42$\n",
    "\n",
    "* Dummy Classifier:\n",
    "    * Accuracy: $0.5$\n",
    "    * Binary F1: $0$\n",
    "    * Binary Precision: $0$\n",
    "    * Binary Recall: $0$\n",
    "\n",
    "* Naive Bayes:\n",
    "    * Accuracy: $0.5$ or $50$%\n",
    "    * Binary F1: $0$\n",
    "    * Binary Precision: $0$\n",
    "    * Binary Recall: $0$\n",
    "\n",
    "* Forest Classifier:\n",
    "    * We ran our forest classifier implementation with the following settings:\n",
    "    * $1000$ weak learners\n",
    "    * $15$ better learners\n",
    "    * $4$ random attribute subsets  \n",
    "    * Our resulting accuracy was $0.78$, or $78$%.\n",
    "\n",
    "**Results**:\n",
    "* Out of all the results the Linear Regressor had highest score in all 4 categories:\n",
    "    1. Accuracy\n",
    "    1. Binary F1\n",
    "    1. Binary Precision\n",
    "    1. Binary Recall\n",
    "    \n",
    "* However, our forest classifier had the best accuracy at $78$%.  Because of this, we used it in our Heroku app.\n",
    "\n",
    "* Our forest classifier also surpasses the dataset's classifier accuracy of $50.18$%.  Pretty neat!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion)\n",
    "\n",
    "* Potential Improvements\n",
    "    * We implemented all of our ideas for improving classification in our dataset.  We believe that further improving the accuracy of our classifier would require implementing more production-style algorithms (as in more accurate sklearn implementations), which are beyond our scope.\n",
    "\n",
    "    * We did not encounter and challenges in the classification of our dataset after we achieved equal class distributions in our dataset.\n",
    "\n",
    "* Key Code Components:\n",
    "\n",
    "```py\n",
    "def generate_weak_forest(X_remainder, y_remainder, N, F, random_state=None):\n",
    "    \"\"\"\n",
    "    generates a weak forest of size N\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_remainder : list\n",
    "        list of lists of attributes\n",
    "    y_remainder : list\n",
    "        list of labels\n",
    "    N : int\n",
    "        number of trees in the forest\n",
    "    F : int\n",
    "        the size of the randomly generated subset of the data\n",
    "    \"\"\"\n",
    "    if random_state is not None:\n",
    "        # print(\"seed\", random_state)\n",
    "        np.random.seed(random_state)\n",
    "    weak_forest = []\n",
    "    for i in range(N):\n",
    "        X_subset = []\n",
    "        y_subset = []\n",
    "        for j in range(F):\n",
    "            # this has a chance of being a duplicate\n",
    "            rand_index = np.random.randint(0, len(X_remainder))\n",
    "            if X_remainder[rand_index] not in X_subset:\n",
    "                X_subset.append(X_remainder[rand_index])\n",
    "                y_subset.append(y_remainder[rand_index])\n",
    "        # now that we have the subset, we can create the tree\n",
    "        tree = myclassifiers.MyDecisionTreeClassifier()\n",
    "        tree.fit(X_subset, y_subset)\n",
    "        weak_forest.append(tree)\n",
    "    return weak_forest\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7813641900121803\n"
     ]
    }
   ],
   "source": [
    "mytable.drop_cols(['isFlaggedFraud']) # we dont need step, nameOrig, nameDest, isFlaggedFraud\n",
    "\n",
    "# we also will make x and y\n",
    "X = []\n",
    "y = []\n",
    "for row in mytable.data:\n",
    "    X.append(row[0:len(row)-1])\n",
    "    y.append(row[-1])\n",
    "\n",
    "# creating our training and test sets\n",
    "X_train_folds_indexes, X_test_folds_indexes = myevaluation.kfold_cross_validation(X,13) # 13 proved to be our most accurate # of folds\n",
    "\n",
    "X_test_folds, X_train_folds, y_test_folds, y_train_folds = myutils.indexes_to_fold(X_test_folds_indexes, X_train_folds_indexes, X, y)\n",
    "X_test, X_train, y_test, y_train = myutils.folds_to_train_test(X_test_folds, X_train_folds, y_test_folds, y_train_folds)\n",
    "\n",
    "# declare threshholds for the forest classifier\n",
    "n = 1000\n",
    "m = 15\n",
    "f = 4\n",
    "\n",
    "forest_clf = myclassifiers.MyRandomForestClassifier(random_state=100)\n",
    "forest_clf.fit(X, y, n, m, f)\n",
    "y_predicted = forest_clf.predict(X_test)\n",
    "accuracy = myevaluation.accuracy_score(y_test, y_predicted)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for local forest: 0.7813641900121803\n",
      "Accuracy for deployed forest: 0.7813641900121803\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "responses = []\n",
    "\n",
    "n = 1000\n",
    "m = 15\n",
    "f = 4\n",
    "\n",
    "# for the presentation, to save time we will be use less data\n",
    "\n",
    "y_predicted = []\n",
    "forest_clf = myclassifiers.MyRandomForestClassifier(random_state=100)\n",
    "forest_clf.fit(X, y, n, m, f)\n",
    "\n",
    "online_predicted = []\n",
    "\n",
    "for instance in X_test:\n",
    "    url = \"http://127.0.0.1:5001/\" # could also be https://financial-fraud-classifier.herokuapp.com/ \n",
    "    # but to save time in the presentation we will use the local server\n",
    "\n",
    "    types = instance[0]\n",
    "    amount = instance[1]\n",
    "    oldbalanceOrg = instance[2]\n",
    "    newbalanceOrig = instance[3]\n",
    "    oldbalanceDest = instance[4]\n",
    "    newbalanceDest = instance[5]\n",
    "    url += \"predict?type=\" + str(types) + \"&amount=\" + str(amount) + \"&oldbalanceOrg=\" + str(oldbalanceOrg) + \"&newbalanceOrig=\" + \\\n",
    "        str(newbalanceOrig) + \"&oldbalanceDest=\" + \\\n",
    "        str(oldbalanceDest) + \"&newbalanceDest=\" + str(newbalanceDest)\n",
    "\n",
    "    response = requests.get(url)\n",
    "    dictionary_version = dict(response.json())\n",
    "\n",
    "    online_predicted.append(dictionary_version[\"prediction\"][0])\n",
    "    y_predicted.append(forest_clf.predict([instance])[0])\n",
    "\n",
    "\n",
    "accuracy = myevaluation.accuracy_score(y_test, y_predicted)\n",
    "print(\"Accuracy for local forest:\", accuracy)\n",
    "\n",
    "accuracy = myevaluation.accuracy_score(y_test, online_predicted)\n",
    "print(\"Accuracy for deployed forest:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some test links:\n",
    "#### Fraud:\n",
    "* https://financial-fraud-classifier.herokuapp.com/predict?type=4&amount=25529.76&oldbalanceOrg=25529.76&newbalanceOrig=0.0&oldbalanceDest=9798.98&newbalanceDest=35328.74 \n",
    "\n",
    "* https://financial-fraud-classifier.herokuapp.com/predict?type=4&amount=290090.57&oldbalanceOrg=290090.57&newbalanceOrig=0.0&oldbalanceDest=2000395.18&newbalanceDest=2290485.75* \n",
    "* https://financial-fraud-classifier.herokuapp.com/predict?type=2&amount=2154005.71&oldbalanceOrg=2154005.71&newbalanceOrig=0.0&oldbalanceDest=0.0&newbalanceDest=0.0 \n",
    "\n",
    "#### Non-Fraudulent: \n",
    "* https://financial-fraud-classifier.herokuapp.com/predict?type=3&amount=180941.96&oldbalanceOrg=9343.0&newbalanceOrig=190284.96&oldbalanceDest=0.0&newbalanceDest=0.0 \n",
    "\n",
    "* https://financial-fraud-classifier.herokuapp.com/predict?type=0&amount=8842.23&oldbalanceOrg=25081.04&newbalanceOrig=16238.82&oldbalanceDest=0.0&newbalanceDest=0.0 \n",
    "\n",
    "* https://financial-fraud-classifier.herokuapp.com/predict?type=3&amount=85491.08&oldbalanceOrg=2217709.25&newbalanceOrig=2303200.33&oldbalanceDest=3404000.21&newbalanceDest=3318509.13 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Contributions\n",
    "    * Ben handled our classification and classifier evaluation.  \n",
    "    * Sam handled our EDA and bringing our work into both the presentation and final report.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sources:\n",
    "    * Dataset:\n",
    "        * https://www.kaggle.com/datasets/vardhansiramdasu/fraudulent-transactions-prediction?resource=download\n",
    "    * Images:\n",
    "        * https://www.istockphoto.com/illustrations/elder-fraud\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
