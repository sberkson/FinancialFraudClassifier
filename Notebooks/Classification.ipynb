{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mysklearn import myclassifiers, myevaluation, mypytable, myutils\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['step', 'type', 'amount', 'nameOrig', 'oldbalanceOrg', 'newbalanceOrig', 'nameDest', 'oldbalanceDest', 'newbalanceDest', 'isFraud', 'isFlaggedFraud']\n",
      "[241.0, 'CASH_OUT', 325470.07, 'C570536992', 325470.07, 0.0, 'C437423112', 19771.15, 345241.22, 1.0, 0.0]\n",
      "['CASH_OUT', 325470.07, 325470.07, 0.0, 19771.15, 345241.22, 1.0]\n",
      "['type', 'amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest', 'isFraud']\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(mypytable)\n",
    "# first we are going to import the dataset into a mypytable object\n",
    "mytable = mypytable.MyPyTable()\n",
    "mytable.load_from_file(\"input_data/Fraud_chop.csv\")\n",
    "\n",
    "print(mytable.column_names)\n",
    "\n",
    "print(mytable.data[0])\n",
    "\n",
    "# we know from my datachoping notebook what each column is and does\n",
    "# mytable.drop_cols(['step','type','nameOrig', 'oldbalanceOrg', 'newbalanceOrig', 'nameDest', 'oldbalanceDest', 'newbalanceDest', 'isFlaggedFraud'])\n",
    "mytable.drop_cols(['step','nameOrig', 'nameDest', 'isFlaggedFraud']) # we dont need step, nameOrig, nameDest, isFlaggedFraud\n",
    "# this is because:\n",
    "# step: this is just the time from the start of the data collection\n",
    "# nameOrig: this is the name of the person who sent the money\n",
    "# nameDest: this is the name of the person who received the money\n",
    "# isFlaggedFraud: this is the classification results for the AI that the group that collected the data created\n",
    "\n",
    "print(mytable.data[0])\n",
    "print(mytable.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TRANSFER', 'PAYMENT', 'DEBIT', 'CASH_OUT', 'CASH_IN']\n",
      "['CASH_OUT', 'CASH_IN', 'TRANSFER', 'DEBIT', 'PAYMENT']\n"
     ]
    }
   ],
   "source": [
    "# the values of type are strings, so we will convert them to ints to be able to be used in the classifiers\n",
    "mytable.convert_col_to_int('type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mytable.data\n",
    "headers = mytable.column_names\n",
    "\n",
    "# we also will make x and y\n",
    "X = []\n",
    "y = []\n",
    "for row in data:\n",
    "    X.append(row[0:len(row)-1])\n",
    "    y.append(row[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_folds_indexes, X_test_folds_indexes = myevaluation.kfold_cross_validation(X,13)\n",
    "\n",
    "X_test_folds,X_train_folds,y_test_folds,y_train_folds = myutils.indexes_to_fold(X_test_folds_indexes, X_train_folds_indexes, X, y)\n",
    "X_test,X_train,y_test,y_train = myutils.folds_to_train_test(X_test_folds,X_train_folds,y_test_folds,y_train_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy accuracy: 0.5\n",
      "Dummy Binary F1: 0\n",
      "Dummy Binary precision: 0\n",
      "Dummy Binary recall: 0\n"
     ]
    }
   ],
   "source": [
    "dummy_clf = myclassifiers.MyDummyClassifier()\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "dummy_Y_predicted = dummy_clf.predict(X_test)\n",
    "\n",
    "dummy_accuracy = myevaluation.accuracy_score(y_test, dummy_Y_predicted)\n",
    "dummy_BinaryF1 = myevaluation.binary_f1_score(y_test, dummy_Y_predicted)\n",
    "dummy_Binary_precision = myevaluation.binary_precision_score(y_test, dummy_Y_predicted)\n",
    "dummy_Binary_recall = myevaluation.binary_recall_score(y_test, dummy_Y_predicted)\n",
    "\n",
    "print(\"Dummy accuracy:\", dummy_accuracy)\n",
    "print(\"Dummy Binary F1:\", dummy_BinaryF1)\n",
    "print(\"Dummy Binary precision:\", dummy_Binary_precision)\n",
    "print(\"Dummy Binary recall:\", dummy_Binary_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes accuracy: 0.5\n",
      "Naive Bayes Binary F1: 0\n",
      "Naive Bayes Binary precision: 0\n",
      "Naive Bayes Binary recall: 0\n"
     ]
    }
   ],
   "source": [
    "NaiveBayes_clf = myclassifiers.MyNaiveBayesClassifier()\n",
    "NaiveBayes_clf.fit(X_train, y_train)\n",
    "NaiveBayes_Y_predicted = NaiveBayes_clf.predict(X_test)\n",
    "\n",
    "NB_accuracy = myevaluation.accuracy_score(y_test, NaiveBayes_Y_predicted, normalize=True)\n",
    "NB_BinaryF1 = myevaluation.binary_f1_score(y_test, NaiveBayes_Y_predicted)\n",
    "NB_Binary_precision = myevaluation.binary_precision_score(y_test, NaiveBayes_Y_predicted)\n",
    "NB_Binary_recall = myevaluation.binary_recall_score(y_test, NaiveBayes_Y_predicted)\n",
    "\n",
    "print(\"Naive Bayes accuracy:\", NB_accuracy)\n",
    "print(\"Naive Bayes Binary F1:\", NB_BinaryF1)\n",
    "print(\"Naive Bayes Binary precision:\", NB_Binary_precision)\n",
    "print(\"Naive Bayes Binary recall:\", NB_Binary_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regressor accuracy: 0.47320341047503045\n",
      "Linear Regressor Binary F1: 0.4444444444444444\n",
      "Linear Regressor Binary precision: 0.4701086956521739\n",
      "Linear Regressor Binary recall: 0.42143727161997563\n"
     ]
    }
   ],
   "source": [
    "reg_clf = myclassifiers.MySimpleLinearRegressor()\n",
    "reg_clf.fit(X_train, y_train)\n",
    "reg_y_predicted = reg_clf.predict(X_test)\n",
    "\n",
    "reg_y_predicted_rounded = []\n",
    "for val in reg_y_predicted:\n",
    "    reg_y_predicted_rounded.append(round(val))\n",
    "\n",
    "reg_accuracy = myevaluation.accuracy_score(y_test, reg_y_predicted_rounded)\n",
    "reg_BinaryF1 = myevaluation.binary_f1_score(y_test, reg_y_predicted_rounded)\n",
    "reg_Binary_precision = myevaluation.binary_precision_score(y_test, reg_y_predicted_rounded)\n",
    "reg_Binary_recall = myevaluation.binary_recall_score(y_test, reg_y_predicted_rounded)\n",
    "\n",
    "print(\"Linear Regressor accuracy:\", reg_accuracy)\n",
    "print(\"Linear Regressor Binary F1:\", reg_BinaryF1)\n",
    "print(\"Linear Regressor Binary precision:\", reg_Binary_precision)\n",
    "print(\"Linear Regressor Binary recall:\", reg_Binary_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results:\n",
    "* Out of all the results the Linear Regressor had highest score in all 4 categories:\n",
    "    1. Accuracy\n",
    "    1. Binary F1\n",
    "    1. Binary Precision\n",
    "    1. Binary Recall\n",
    "* because of this, we will be using the Linear Regressor for the Heroku App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7813641900121803\n"
     ]
    }
   ],
   "source": [
    "n = 1000\n",
    "m = 15\n",
    "f = 4\n",
    "\n",
    "forest_clf = myclassifiers.MyRandomForestClassifier(random_state=100)\n",
    "forest_clf.fit(X, y, n, m, f)\n",
    "y_predicted = forest_clf.predict(X_test)\n",
    "accuracy = myevaluation.accuracy_score(y_test, y_predicted)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5f8c5c8ab154ffd7b7cf769370d90abd279d12a3d937a702f83e9fc02204b3d3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
