{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mysklearn import myclassifiers, myevaluation, mypytable, myutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['step', 'type', 'amount', 'nameOrig', 'oldbalanceOrg', 'newbalanceOrig', 'nameDest', 'oldbalanceDest', 'newbalanceDest', 'isFraud', 'isFlaggedFraud']\n"
     ]
    }
   ],
   "source": [
    "# first we are going to import the dataset into a mypytable object\n",
    "mytable = mypytable.MyPyTable()\n",
    "mytable.load_from_file(\"Fraud_chop.csv\")\n",
    "print(mytable.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "7\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "# we know from my datachoping notebook what each column is and does, so for this example we are going to \n",
    "# ignore nameOrig (index of 3) nameDest (index of 6)\n",
    "# we will also be dropping isFlaggedFraud (index of -1)\n",
    "data = []\n",
    "print(len(mytable.column_names))\n",
    "for row in mytable.data:\n",
    "    new_row = []\n",
    "    for i in range(len(mytable.column_names) -1): # not using the last one\n",
    "        if i != 1 and i != 3 and i != 6:\n",
    "            new_row.append(row[i])\n",
    "    data.append(new_row)\n",
    "headers = []\n",
    "for i in range(len(mytable.column_names) -1): # not using the last one\n",
    "    if i != 1 and i != 3 and i != 6:\n",
    "        headers.append(mytable.column_names[i])\n",
    "print(len(headers))\n",
    "print(len(data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7750\n",
      "7750\n"
     ]
    }
   ],
   "source": [
    "# we also will make x and y\n",
    "X = []\n",
    "y = []\n",
    "for row in data:\n",
    "    X.append(row[0:len(row)-1])\n",
    "    y.append(row[-1])\n",
    "print(len(y))\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_folds, X_test_folds = myevaluation.stratified_kfold_cross_validation(X, y,10)\n",
    "\n",
    "X_test_folds,X_train_folds,y_test_folds,y_train_folds = myutils.indexes_to_fold(X_test_folds, X_train_folds, X, y)\n",
    "X_test,X_train,y_test,y_train = myutils.folds_to_train_test(X_test_folds,X_train_folds,y_test_folds,y_train_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_clf = myclassifiers.MyDummyClassifier()\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "dummy_Y_predicted = dummy_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy accuracy: 0.9987096774193548\n",
      "Dummy Binary F1: 0.9993544222078761\n",
      "Dummy Binary precision: 0.9987096774193548\n",
      "Dummy Binary recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "dummy_accuracy = myevaluation.accuracy_score(y_test, dummy_Y_predicted)\n",
    "dummy_BinaryF1 = myevaluation.binary_f1_score(y_test, dummy_Y_predicted)\n",
    "dummy_Binary_precision = myevaluation.binary_precision_score(y_test, dummy_Y_predicted)\n",
    "dummy_Binary_recall = myevaluation.binary_recall_score(y_test, dummy_Y_predicted)\n",
    "\n",
    "print(\"Dummy accuracy:\", dummy_accuracy)\n",
    "print(\"Dummy Binary F1:\", dummy_BinaryF1)\n",
    "print(\"Dummy Binary precision:\", dummy_Binary_precision)\n",
    "print(\"Dummy Binary recall:\", dummy_Binary_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NaiveBayes_clf = myclassifiers.MyNaiveBayesClassifier()\n",
    "NaiveBayes_clf.fit(X_train, y_train)\n",
    "NaiveBayes_Y_predicted = NaiveBayes_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes accuracy: 0.0012903225806451613\n",
      "Naive Bayes Binary F1: 0\n",
      "Naive Bayes Binary precision: 0\n",
      "Naive Bayes Binary recall: 0\n"
     ]
    }
   ],
   "source": [
    "NB_accuracy = myevaluation.accuracy_score(y_test, NaiveBayes_Y_predicted, normalize=True)\n",
    "NB_BinaryF1 = myevaluation.binary_f1_score(y_test, NaiveBayes_Y_predicted)\n",
    "NB_Binary_precision = myevaluation.binary_precision_score(y_test, NaiveBayes_Y_predicted)\n",
    "NB_Binary_recall = myevaluation.binary_recall_score(y_test, NaiveBayes_Y_predicted)\n",
    "\n",
    "print(\"Naive Bayes accuracy:\", NB_accuracy)\n",
    "print(\"Naive Bayes Binary F1:\", NB_BinaryF1)\n",
    "print(\"Naive Bayes Binary precision:\", NB_Binary_precision)\n",
    "print(\"Naive Bayes Binary recall:\", NB_Binary_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf = myclassifiers.MyDecisionTreeClassifier()\n",
    "tree_clf.fit(X_train, y_train)\n",
    "tree_Y_predicted = tree_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree accuracy: 1.0\n",
      "Decision Tree Binary F1: 1.0\n",
      "Decision Tree Binary precision: 1.0\n",
      "Decision Tree Binary recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "tree_accuracy = myevaluation.accuracy_score(y_test, tree_Y_predicted, normalize=True)\n",
    "tree_BinaryF1 = myevaluation.binary_f1_score(y_test, tree_Y_predicted)\n",
    "tree_Binary_precision = myevaluation.binary_precision_score(y_test, tree_Y_predicted)\n",
    "tree_Binary_recall = myevaluation.binary_recall_score(y_test, tree_Y_predicted)\n",
    "\n",
    "print(\"Decision Tree accuracy:\", tree_accuracy)\n",
    "print(\"Decision Tree Binary F1:\", tree_BinaryF1)\n",
    "print(\"Decision Tree Binary precision:\", tree_Binary_precision)\n",
    "print(\"Decision Tree Binary recall:\", tree_Binary_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(tree_Y_predicted.count(1))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5f8c5c8ab154ffd7b7cf769370d90abd279d12a3d937a702f83e9fc02204b3d3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
